# -*- coding: utf-8 -*-
"""Assignment2_2201680.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1onASm27NTDSEZ_90GCgLDl1J8kU9AFpj
"""

import pandas as pd
import glob
import numpy as np
import os
import seaborn as sns
from matplotlib import pyplot as plt
import datetime
import warnings
warnings.filterwarnings('ignore')

"""# Data Perprocessing Starts"""

all_folders = [x[0] for x in os.walk(r"C:\Users\USER\Desktop\CE888-ASSIGNMENT\Stress-Predict-Dataset-main\Raw_data")]

#only selecting the necessary folders which contains subject s01 to subject s35 data
all_folders = all_folders[1:]

pre = pd.read_csv(r'C:\Users\USER\Desktop\CE888-ASSIGNMENT\Stress-Predict-Dataset-main\Processed_data\Improved_All_Combined_hr_rsp_binary.csv')
pre.rename({'Time(sec)':'merger'},axis = 1,inplace = True)

all_folders

count = 0
final_data = pd.DataFrame()
testing_data = pd.DataFrame()

for i in all_folders:

    files = []
    for j in glob.glob(i + "/*.csv"):
        files.append(j)
        
    acc = pd.read_csv(files[0])
    bvp = pd.read_csv(files[1])
    eda = pd.read_csv(files[2])
    hr = pd.read_csv(files[3])
    ibi = pd.read_csv(files[4])
    temp = pd.read_csv(files[6])
    
    acc['merger'] = 0
    bvp['merger'] = 0
    hr['merger'] = 0
    eda['merger'] = 0
    ibi['merger'] = 0
    temp['merger'] = 0
    
    acc['merger'] = int(float(acc.columns[0]))
    bvp['merger'] = int(float(bvp.columns[0]))
    eda['merger'] = int(float(eda.columns[0]))
    hr['merger'] = int(float(hr.columns[0]))
    ibi['merger'] = int(float(ibi.columns[0]))
    temp['merger'] = int(float(temp.columns[0]))
    
    acc.reset_index(inplace = True)
    bvp.reset_index(inplace = True)
    hr.reset_index(inplace = True)
    ibi.reset_index(inplace = True)
    temp.reset_index(inplace = True)
    eda.reset_index(inplace = True)
    
    acc['merger'] = acc['merger']+acc['index']
    bvp['merger'] = bvp['merger']+bvp['index']
    ibi['merger'] = ibi['merger']+ibi['index']
    eda['merger'] = eda['merger']+eda['index']
    temp['merger'] = temp['merger']+temp['index']
    hr['merger'] = hr['merger']+hr['index']
    
    acc.drop('index',axis = 1,inplace = True)
    bvp.drop('index',axis = 1,inplace = True)
    hr.drop('index',axis = 1,inplace = True)
    ibi.drop('index',axis = 1,inplace = True)
    temp.drop('index',axis = 1,inplace = True)
    eda.drop('index',axis = 1,inplace = True)
    
    acc.rename({acc.columns[0]:'X',acc.columns[1]:'Y',acc.columns[2]:'Z'},axis = 1,inplace = True)
    bvp.rename({bvp.columns[0]:'bvp'},axis = 1,inplace = True)
    hr.rename({hr.columns[0]:'hr'},axis = 1,inplace = True)
    ibi.rename({ibi.columns[0]:'IBI0'},axis = 1,inplace = True)
    temp.rename({temp.columns[0]:'temp'},axis = 1,inplace = True)
    eda.rename({eda.columns[0]:'eda'},axis = 1,inplace = True)
    
    final = acc.merge(bvp,on = 'merger',how = 'outer').merge(hr,on = 'merger',how = 'outer').merge(ibi,on = 'merger',how = 'outer').merge(temp,on = 'merger',how = 'outer').merge(eda,on = 'merger',how = 'outer')
    
    def dt(x):
        return datetime.datetime.fromtimestamp(x)

    final['datetime'] = final['merger'].apply(dt)
    
    final.reset_index(inplace = True, drop = True)
    
    final.fillna(method='ffill',inplace = True)
    final.fillna(method='bfill',inplace = True)
    
    final = final.merge(pre[['merger','Label']],on = 'merger',how = 'inner')
    
    if count == 0:
        testing_data = testing_data.append(final)
    else:
        final_data = final_data.append(final)
    final_data.reset_index(inplace = True, drop = True)

    count = count + 1
    print('Subject', count,'is done')

testing_data.to_csv('test.csv',index = False)
final_data.to_csv('preprocessed.csv',index = False)

"""# Data Preprocessing Ends"""

import pandas as pd
import glob
import numpy as np
import os
import seaborn as sns
from matplotlib import pyplot as plt
import datetime
import warnings
warnings.filterwarnings('ignore')

train = pd.read_csv('preprocessed.csv')
test = pd.read_csv('test.csv')

train.head()

test.head()

train.info()

train.duplicated().sum()

test.duplicated().sum()

#dropping duplicates
train.drop_duplicates(inplace = True)
test.drop_duplicates(inplace = True)

train.describe()

train.corr()

sns.heatmap(train.corr(),annot = True)

#checking skewed data
train.hist(figsize = (10,10))



plt.figure(figsize=(10, 6))

# Plot the timeseries data
print(plt.plot(final_data.datetime, final_data.X))

plt.figure(figsize=(10, 10))

print(plt.plot(final_data.datetime, final_data.Y))

plt.figure(figsize=(10, 10))

print(plt.plot(final_data.datetime, final_data.Z))

train['Label'].value_counts()

#checking the label counts
sns.countplot(train['Label'])

"""# Resampling"""

#downsampling the data
from sklearn.utils import resample

df_A = train[train['Label'] == 0]
df_B = train[train['Label'] == 1]

df_A_downsampled = resample(df_A, replace=False, n_samples=len(df_B), random_state=100)
train = pd.concat([df_A_downsampled, df_B])

train['Label'].value_counts()

sns.countplot(train['Label'])

"""# train test split"""

#splitting the data
from sklearn.model_selection import train_test_split

X = train.drop({'merger','Label','datetime'},axis = 1)
y = train['Label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=100)

X_train.shape, y_train.shape

X_test.shape, y_test.shape

"""# Model building

# Logistic Regression
"""

from sklearn.linear_model import LogisticRegression

clf = LogisticRegression(random_state=0).fit(X_train, y_train)
y_pred1 = clf.predict(X_test)

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred1))

from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, y_pred1)

from sklearn import metrics

confusion_matrix = metrics.confusion_matrix(y_test, y_pred1)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])

cm_display.plot()
plt.show()

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier

clf1 = RandomForestClassifier(max_depth=2, random_state=0).fit(X_train, y_train)
y_pred2 = clf1.predict(X_test)

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred2))

from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, y_pred2)

from sklearn import metrics

confusion_matrix = metrics.confusion_matrix(y_test, y_pred2)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])

cm_display.plot()
plt.show()

"""# Naive bayes"""

from sklearn.naive_bayes import GaussianNB

clf2 = GaussianNB().fit(X_train, y_train)
y_pred3 = clf2.predict(X_test)

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred3))

from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, y_pred3)

from sklearn import metrics

confusion_matrix = metrics.confusion_matrix(y_test, y_pred3)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])

cm_display.plot()
plt.show()

"""# Gradient Boosting"""

from sklearn.ensemble import GradientBoostingClassifier

clf3 = GradientBoostingClassifier().fit(X_train, y_train)
y_pred4 = clf3.predict(X_test)

print(classification_report(y_test, y_pred4))

from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, y_pred4)

from sklearn import metrics

confusion_matrix = metrics.confusion_matrix(y_test, y_pred4)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])

cm_display.plot()
plt.show()

subject1 = clf1.predict(test.drop({'merger','Label','datetime'},axis = 1))

#subject1 testing
subject1

